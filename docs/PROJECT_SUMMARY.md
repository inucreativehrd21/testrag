# Git/Python RAG ì±—ë´‡ ìµœì í™” í”„ë¡œì íŠ¸ ë³´ê³ ì„œ

**í”„ë¡œì íŠ¸ ê¸°ê°„**: 2025-11-19 (1ì¼ ì§‘ì¤‘ ìµœì í™”)
**ëª©í‘œ**: RAGAS ì„±ëŠ¥ ì§€í‘œ ê°œì„  (Faithfulness 45% â†’ 93%+, Answer Correctness 44% â†’ 75%+)
**ë„ë©”ì¸**: Git & Python ê°œë°œ í•™ìŠµ ë„ìš°ë¯¸

---

## ğŸ“Š 1. ì´ˆê¸° ìƒí™© ë¶„ì„

### 1.1 RAGAS í‰ê°€ ê²°ê³¼ (Initial)
```
Evaluation Results (16 questions):
- Faithfulness: 45.31% (ë§¤ìš° ë‚®ìŒ, í™˜ê° ë¬¸ì œ ì‹¬ê°)
- Answer Relevancy: 69.77%
- Context Precision: 65.44%
- Context Recall: 67.77%
- Answer Correctness: 44.03% (ê°€ì¥ ì‹¬ê°)
```

### 1.2 ê·¼ë³¸ ì›ì¸ ë¶„ì„

**ë¬¸ì œ 1: ë„ë©”ì¸ ê³¼í™•ì¥**
- ê¸°ì¡´: Git, Python, Docker, AWS 4ê°œ ë„ë©”ì¸ ë™ì‹œ ì§€ì›
- Docker/AWS ë¬¸ì„œ ë¶€ì¡±ìœ¼ë¡œ Advanced ë‚œì´ë„ ì§ˆë¬¸ ë‹µë³€ ë¶ˆê°€
- ê²°ê³¼: í‰ê°€ ì§ˆë¬¸ì˜ 25%ê°€ ë‹µë³€ ë¶ˆê°€ â†’ ì „ì²´ ì ìˆ˜ í•˜ë½

**ë¬¸ì œ 2: Hyperparameter ë¯¸ê²€ì¦**
- Top-k=50, rerank_top_k=5 ë“± íŒŒë¼ë¯¸í„°ê°€ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ì´ ì•„ë‹˜
- ì²­í‚¹ í¬ê¸°(1024 chars)ê°€ ë¬¸ì„œ ë¶„í¬(Median=899)ì™€ ë¶ˆì¼ì¹˜
- ë¹„íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±

**ë¬¸ì œ 3: ë‹µë³€ ìŠ¤íƒ€ì¼ ë¬¸ì œ**
- í˜•ì‹ì ì´ê³  ì¥í™©í•œ ë‹µë³€ (15-20ì¤„)
- ê³¼ë„í•œ êµ¬ì¡°í™”: "ìš”ì•½:", "ì„¸ë¶€ ë‹¨ê³„:", "[ì¦ê±° ìš”ì•½]", "[ìì²´ ê²€ì¦]"
- ì¶œì²˜ í‘œì‹œ ë¬¸ì œ: "ê·¼ê±° 1, ê·¼ê±° 2" (ì‹¤ì œ íŒŒì¼ëª… ì—†ìŒ)
- ì‚¬ìš©ì ê²½í—˜ ì €í•˜

---

## ğŸ¯ 2. ìµœì í™” ì „ëµ ë° ì‹¤í–‰

### Phase 1: ë„ë©”ì¸ ì¶•ì†Œ ë° Enhanced Pipeline êµ¬í˜„

#### 2.1 ë„ë©”ì¸ ì§‘ì¤‘í™”
**ê²°ì •**: Docker/AWS ì œì™¸, Git/Pythonë§Œ ì§‘ì¤‘
```yaml
# config/enhanced.yaml
data:
  domains: [git, python]  # ê¸°ì¡´ 4ê°œ â†’ 2ê°œ
```

**ê·¼ê±°**:
- Git/Python ë¬¸ì„œ: ì¶©ë¶„í•œ ì»¤ë²„ë¦¬ì§€ (12,796 chunks)
- Docker/AWS: ë¬¸ì„œ ë¶€ì¡±ìœ¼ë¡œ Advanced ì§ˆë¬¸ ë‹µë³€ ë¶ˆê°€
- ì§‘ì¤‘í™”ë¥¼ í†µí•œ í’ˆì§ˆ í–¥ìƒ ì „ëµ

---

#### 2.2 Enhanced RAG Pipeline êµ¬í˜„ (answerer_v2.py)

**êµ¬í˜„ ë‚´ìš©**:

**1) Hybrid Search (Dense + Sparse + RRF)**
```python
# Dense Search (Semantic)
dense_results = self.collection.query(query_embeddings=[query_dense], n_results=50)

# Sparse Search (Keyword, BM25-like)
sparse_scores = self._sparse_search(query_sparse, dense_docs, top_k=50)

# Reciprocal Rank Fusion (RRF)
rrf_scores[doc_id] = 1.0 / (k + dense_rank + 1) + 1.0 / (k + sparse_rank + 1)
```

**íš¨ê³¼**:
- Dense: ì˜ë¯¸ì  ìœ ì‚¬ë„ ê²€ìƒ‰
- Sparse: í‚¤ì›Œë“œ ë§¤ì¹­ (ì „ë¬¸ ìš©ì–´ ê°•í™”)
- RRF: ë‘ ë°©ì‹ì˜ ì¥ì  í†µí•© (k=60)

**ì°¸ê³  ë…¼ë¬¸**: "Reciprocal Rank Fusion outperforms Condorcet" (SIGIR 2009)

---

**2) Context Quality Filter (Self-RAG Style)**
```python
def _evaluate_context_quality(self, question, contexts):
    # gpt-4o-minië¡œ ê° ì»¨í…ìŠ¤íŠ¸ í‰ê°€
    # RELEVANT / PARTIAL / IRRELEVANT ë¶„ë¥˜
    # IRRELEVANTëŠ” LLMì— ì „ë‹¬í•˜ì§€ ì•ŠìŒ
```

**íš¨ê³¼**:
- ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ í•„í„°ë§ â†’ Precision â†‘
- í™˜ê°(hallucination) ê°ì†Œ â†’ Faithfulness â†‘
- ë¹„ìš© íš¨ìœ¨ì  (gpt-4o-mini ì‚¬ìš©)

**ì°¸ê³  ë…¼ë¬¸**: "Self-RAG: Learning to Retrieve, Generate, and Critique" (Asai et al., 2023)

---

**3) Two-Stage Reranking (ì´ë¯¸ êµ¬í˜„ë¨, í™•ì¸)**
```yaml
rerankers:
  stage1:
    model_name: BAAI/bge-reranker-v2-m3
    device: cuda:0
  stage2:
    model_name: BAAI/bge-reranker-large
    device: cuda:1
```

**íš¨ê³¼**:
- Stage 1: ë¹ ë¥¸ ì‚¬ì „ í•„í„°ë§
- Stage 2: ì •ë°€í•œ ìµœì¢… ìˆœìœ„ ê²°ì •

---

### Phase 2: ë°ì´í„° ê¸°ë°˜ Hyperparameter ìµœì í™”

#### 2.3 ë¬¸ì„œ ë¶„í¬ ë¶„ì„ (analyze_documents.py)

**ë¶„ì„ ë„êµ¬ ê°œë°œ**:
```bash
python analyze_documents.py --chunks artifacts/chunks.parquet
# ì¶œë ¥: document_analysis.png (6ê°œ ì°¨íŠ¸), statistics.json
```

**ë¶„ì„ ê²°ê³¼** (Git/Python 12,796 chunks):
```
Overall Statistics:
- Mean Length: 829 chars
- Median Length: 899 chars  â† í•µì‹¬ ì§€í‘œ
- P75: 969 chars
- P95: 1012 chars

Key Insight: 95%ì˜ ë¬¸ì„œê°€ 1012ì ì´í•˜
```

**ì‹œê°í™”**:
1. ì „ì²´ ë¬¸ì„œ ê¸¸ì´ ë¶„í¬ (Histogram)
2. ë„ë©”ì¸ë³„ ê¸¸ì´ ë¶„í¬ (Git vs Python)
3. Box Plot (ë„ë©”ì¸ë³„ ë¹„êµ)
4. ëˆ„ì  ë¶„í¬ í•¨ìˆ˜ (CDF)
5. ì‹œê°„ì— ë”°ë¥¸ ê¸¸ì´ ë³€í™”
6. ì¶”ì²œ íŒŒë¼ë¯¸í„° ìš”ì•½ í‘œ

---

#### 2.4 ìµœì í™”ëœ Hyperparameters

**1) Chunking Parameters**

| Parameter | Before | After | Rationale |
|-----------|--------|-------|-----------|
| chunk_size | 1024 | **900** | Median=899 ê¸°ì¤€ (50%ì˜ ë¬¸ì„œ ìµœì í™”) |
| chunk_overlap | 150 (14.6%) | **180** (20%) | í‘œì¤€ overlap ratio |

**ê·¼ê±°**:
- P75=969ëŠ” ì•½ê°„ í¼, Mean=829ëŠ” ì•½ê°„ ì‘ìŒ
- 900 = ì¤‘ê°„ì , ê²€ìƒ‰ ì •ë°€ë„ ìµœì 
- 95%ì˜ ë¬¸ì„œë¥¼ 1-2 ì²­í¬ë¡œ ì»¤ë²„
- Overlap 20% = ë¬¸ì¥/ë‹¨ë½ ê²½ê³„ ë³´ì¡´ í‘œì¤€

**ì˜ˆìƒ íš¨ê³¼**:
- Index Size: -12% (ì²­í¬ ìˆ˜ ê°ì†Œ)
- Search Speed: +10-15% (ë” ì ì€ ì²­í¬ ìŠ¤ìº”)
- Precision: +5-8% (ë” ì •í™•í•œ ë§¤ì¹­)

---

**2) Retrieval Top-k Parameters**

| Parameter | Before | After | Rationale |
|-----------|--------|-------|-----------|
| hybrid_dense_top_k | 50 | **50** âœ“ | sqrt(12796)=113ë³´ë‹¤ ì‘ì§€ë§Œ íš¨ìœ¨ì  |
| hybrid_sparse_top_k | 50 | **50** âœ“ | Denseì™€ ë™ì¼ ìœ ì§€ |
| rerank_top_k | 5 | **10** | ì´ˆê¸° ê²€ìƒ‰ì˜ 20% (ì´ìƒì  ë¹„ìœ¨) |
| rrf_k | 60 | **60** âœ“ | í‘œì¤€ê°’ ìœ ì§€ |

**ê·¼ê±°**:
- Total chunks: 12,796
- sqrt(N) = 113 (ì´ë¡ ì  ê¸°ì¤€)
- 3% of N = 384 â†’ capped to 100
- í˜„ì¬ 50ì€ ë³´ìˆ˜ì ì´ì§€ë§Œ, Hybrid + Two-stage Reranking ê³ ë ¤ ì‹œ íš¨ìœ¨ì 
- **rerank_top_k=5ëŠ” ë„ˆë¬´ ì ìŒ** (10% ë¹„ìœ¨)
- 10-20%ê°€ ì´ìƒì  â†’ 10ê°œë¡œ ì¦ê°€

**ì˜ˆìƒ íš¨ê³¼**:
- Context Recall: +10-15%
- Faithfulness: +3-5%
- Reranking Latency: +200-300ms (í—ˆìš© ë²”ìœ„)

---

### Phase 3: System Prompt ìµœì í™” (ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ ë‹µë³€)

#### 2.5 LLM Prompting ì´ë¡  ì ìš©

**ì ìš©ëœ ì£¼ìš” ì´ë¡ **:

**1) Constitutional AI (Anthropic 2022)**
```
í•µì‹¬ ì›ì¹™:
1. ê²€ìƒ‰ëœ ë¬¸ì„œì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€ (í™˜ê° ë°©ì§€)
2. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
3. ë¶ˆí™•ì‹¤í•˜ë©´ ì†”ì§í•˜ê²Œ ë°íˆê¸°
```
â†’ Faithfulness í–¥ìƒ

**2) Few-shot Prompting (Brown et al., 2020)**
- 3ê°œì˜ ì™„ë²½í•œ ì˜ˆì‹œ ì œê³µ (ê°œë… ì„¤ëª…, ì‹¤ìš© ê°€ì´ë“œ, ë¹„êµ ì„¤ëª…)
- í˜•ì‹ë³´ë‹¤ ì˜ˆì‹œê°€ ë” ê°•ë ¥í•¨ (GPTëŠ” íŒ¨í„´ í•™ìŠµ)
â†’ ë‹µë³€ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±

**3) Context Grounding (Self-RAG, 2023)**
```
ë‚´ë¶€ ì‘ì—… íë¦„:
Step 1: ë¬¸ì„œ í‰ê°€ (RELEVANT vs IRRELEVANT)
Step 2: ë‹µë³€ êµ¬ì„± (ê´€ë ¨ ë¬¸ì„œë§Œ ì‚¬ìš©)
Step 3: ê²€ì¦ (ì¶”ì¸¡ ì œê±°)
âš ï¸ ì‚¬ìš©ìì—ê²ŒëŠ” ìµœì¢… ë‹µë³€ë§Œ!
```
â†’ Context Precision í–¥ìƒ

**4) Chain-of-Thought (Wei et al., 2022)**
- ë³µì¡í•œ ì§ˆë¬¸ â†’ ë‚´ë¶€ì ìœ¼ë¡œ ë¶„í•´ â†’ ê°„ê²°í•œ ìµœì¢… ë‹µë³€
â†’ ë³µì¡í•œ ì§ˆë¬¸ í’ˆì§ˆ í–¥ìƒ

**5) Minimal Citation Strategy**
```
ê¸°ë³¸: ë‹µë³€ ëì— "ğŸ“š ì°¸ê³ : [ë¬¸ì„œëª…]"
ì—¬ëŸ¬ ë¬¸ì„œ: "ğŸ“š ì°¸ê³ : [ë¬¸ì„œ1], [ë¬¸ì„œ2]"
âš ï¸ ëª¨ë“  ë¬¸ì¥ë§ˆë‹¤ ì¸ìš©í•˜ì§€ ë§ˆì„¸ìš”!
```
â†’ ê°€ë…ì„± ëŒ€í­ í–¥ìƒ

---

#### 2.6 Before vs After ë¹„êµ

**Before (system.txt)** - í˜•ì‹ì , ì¥í™©í•¨:
```
ìš”ì•½: Pythonì—ì„œ *argsëŠ” ì„ì˜ ê°œìˆ˜ì˜ ìœ„ì¹˜ ì¸ì...

ì„¸ë¶€ ë‹¨ê³„:
1) *args: í•¨ìˆ˜ ì •ì˜ì—ì„œ...
2) **kwargs: í•¨ìˆ˜ ì •ì˜ì—ì„œ...

[ì¦ê±° ìš”ì•½]
- [DOC-1] Python | ...
- [DOC-3] Python | ...

[ì¶œì²˜ ì¸ìš©]
- ... [DOC-2: íŒŒì¼ëª…, ì„¹ì…˜]

[ìì²´ ê²€ì¦]
- ì¶œì²˜ì™€ 100% ì¼ì¹˜: O
```
â†’ **15-20ì¤„**, ê°€ë…ì„± ë‚®ìŒ

**After (system_v2.txt)** - ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•¨:
```
*argsì™€ **kwargsëŠ” í•¨ìˆ˜ì— ê°€ë³€ ê°œìˆ˜ì˜ ì¸ìë¥¼ ì „ë‹¬í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

â€¢ *args: ìœ„ì¹˜ ì¸ìë¥¼ íŠœí”Œë¡œ ë°›ìŒ
â€¢ **kwargs: í‚¤ì›Œë“œ ì¸ìë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°›ìŒ

ì˜ˆì‹œ:
def greet(*args, **kwargs):
    print(args)    # ('Alice', 'Bob')
    print(kwargs)  # {'age': 25, 'city': 'Seoul'}

greet('Alice', 'Bob', age=25, city='Seoul')

í•¨ê»˜ ì‚¬ìš©í•  ë•ŒëŠ” ìˆœì„œê°€ ì¤‘ìš”í•´ìš”: ì¼ë°˜ ì¸ì â†’ *args â†’ í‚¤ì›Œë“œ ì¸ì â†’ **kwargs

ğŸ“š ì°¸ê³ : function-arguments.md
```
â†’ **5-8ì¤„**, ê°€ë…ì„± ë†’ìŒ

---

#### 2.7 ì¶œì²˜ í‘œì‹œ ê°œì„  (ë©”íƒ€ë°ì´í„° í¬í•¨)

**ë¬¸ì œ**:
```python
# Before
context_block = "\n\n".join(f"ê·¼ê±° {i+1}: {chunk}" for i, chunk in enumerate(contexts))
```
â†’ GPTëŠ” "ê·¼ê±° 1", "ê·¼ê±° 2"ë§Œ ë°›ìŒ, ì‹¤ì œ íŒŒì¼ëª… ëª¨ë¦„

**í•´ê²°**:
```python
# After: ChromaDBì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
all_docs_result = self.collection.get(include=["documents", "metadatas"])
text_to_meta = {doc[:200]: meta for doc, meta in zip(all_docs, all_metas)}

# ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
context_block = "\n\n".join(
    f"[ë¬¸ì„œ {i+1}] {ctx['domain']} | {ctx['source']}\n{ctx['text']}"
    for i, ctx in enumerate(context_with_meta)
)
```
â†’ GPTê°€ ì‹¤ì œ **íŒŒì¼ëª…ê³¼ ë„ë©”ì¸** ë°›ìŒ!

**íš¨ê³¼**:
- ì¶œì²˜ í‘œì‹œ: "ê·¼ê±° 1, ê·¼ê±° 2" â†’ "function-arguments.md" âœ…
- ë‹µë³€ ì‹ ë¢°ë„ í–¥ìƒ
- ë””ë²„ê¹… ìš©ì´

---

## ğŸ“ˆ 3. ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

### 3.1 RAGAS ì§€í‘œ ëª©í‘œ

| Metric | Before | Target | Strategy |
|--------|--------|--------|----------|
| **Context Precision** | ~65% | **80%+** | Hybrid Search + Grounding + Filtering |
| **Context Recall** | ~68% | **85%+** | rerank_top_k=10, Hybrid Search |
| **Faithfulness** | ~45% | **93%+** | Constitutional AI, Context Quality Filter |
| **Answer Relevancy** | ~70% | **80%+** | Natural Style, Concise Responses |
| **Answer Correctness** | ~44% | **75%+** | ì¢…í•© ê°œì„  (ëª¨ë“  ì „ëµ í†µí•©) |

### 3.2 ê°œì„  ê·¼ê±°

**1) Chunking ìµœì í™” (1024â†’900)**
- Index Size: -12% (12,796 â†’ ~11,400 chunks)
- Search Speed: +10-15%
- Precision: +5-8%

**2) Reranking ê°•í™” (5â†’10)**
- Context Recall: +10-15%
- Faithfulness: +3-5%
- Answer Correctness: +5-8%

**3) System Prompt ìµœì í™”**
- Answer Relevancy: +10-15%
- ì‚¬ìš©ì ë§Œì¡±ë„: ëŒ€í­ í–¥ìƒ
- ë‹µë³€ ê¸¸ì´: 15ì¤„ â†’ 5-8ì¤„

**4) Context Quality Filter**
- Faithfulness: +15-20%
- Precision: +8-12%

---

## ğŸ› ï¸ 4. ê¸°ìˆ  ìŠ¤íƒ ë° êµ¬í˜„

### 4.1 í•µì‹¬ ì»´í¬ë„ŒíŠ¸

**Embedding Model**:
- BAAI/bge-m3 (Multi-lingual, Multi-functionality)
- Dense + Sparse + ColBERT ì§€ì›
- 1024D dense vector, lexical sparse weights

**Vector Database**:
- ChromaDB
- Metadata ì§€ì› (source, domain)
- 12,796 chunks indexed

**Reranking Models**:
- Stage 1: BAAI/bge-reranker-v2-m3 (ë¹ ë¥¸ í•„í„°ë§)
- Stage 2: BAAI/bge-reranker-large (ì •ë°€ ìˆœìœ„)

**LLM**:
- Main: GPT-4.1 (ë‹µë³€ ìƒì„±)
- Evaluator: GPT-4o-mini (Context Quality Filter)

**ê¸°íƒ€**:
- Python 3.x
- pandas, numpy (ë°ì´í„° ë¶„ì„)
- matplotlib, seaborn (ì‹œê°í™”)

---

### 4.2 ìƒì„±ëœ íŒŒì¼

**ì½”ì–´ íŒŒì¼**:
1. `answerer_v2.py` - Enhanced RAG Pipeline
2. `config/enhanced.yaml` - ìµœì í™”ëœ ì„¤ì •
3. `prompts/system_v2.txt` - ê°œì„ ëœ System Prompt

**ë¶„ì„ ë„êµ¬**:
4. `analyze_documents.py` - ë¬¸ì„œ ë¶„í¬ ë¶„ì„ ë° ì‹œê°í™”
5. `analyze_documents_simple.py` - í…ìŠ¤íŠ¸ ë²„ì „ (ì˜ì¡´ì„± ìµœì†Œ)

**í…ŒìŠ¤íŠ¸/ë¹„êµ**:
6. `test_enhanced.py` - Quick í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
7. `compare_pipelines.py` - Baseline vs Enhanced ë¹„êµ

**ë¬¸ì„œ**:
8. `ENHANCED_README.md` - Enhanced Pipeline ê°€ì´ë“œ
9. `OPTIMIZATION_GUIDE.md` - Hyperparameter ìµœì í™” ê°€ì´ë“œ
10. `PROMPT_OPTIMIZATION.md` - System Prompt ìµœì í™” ê°€ì´ë“œ
11. `PROJECT_SUMMARY.md` - ì´ ë³´ê³ ì„œ

---

## ğŸ“Š 5. ì‹¤í–‰ ê³„íš ë° ê²€ì¦

### 5.1 ì¬ì¸ë±ì‹± (í•„ìˆ˜)

```bash
cd /workspace/rag_pipeline

# ê¸°ì¡´ ì¸ë±ìŠ¤ ë°±ì—…
cp -r artifacts artifacts_backup_1024

# ìƒˆ íŒŒë¼ë¯¸í„°ë¡œ ì¬ì¸ë±ì‹±
python data_prep.py --config config/enhanced.yaml
python index_builder.py --config config/enhanced.yaml
```

**ì´ìœ **: chunk_size ë³€ê²½ (1024 â†’ 900), overlap ë³€ê²½ (150 â†’ 180)

---

### 5.2 í…ŒìŠ¤íŠ¸ ê³„íš

**1) Quick Test (ê°„ë‹¨í•œ ì§ˆë¬¸)**
```bash
python answerer_v2.py "Pythonì—ì„œ *argsì™€ **kwargsëŠ” ë¬´ì—‡ì¸ê°€ìš”?" --config config/enhanced.yaml
python answerer_v2.py "Pythonì—ì„œ ì–•ì€ ë³µì‚¬ì™€ ê¹Šì€ ë³µì‚¬ì˜ ì°¨ì´ëŠ”?" --config config/enhanced.yaml
python answerer_v2.py "git rebaseëŠ” ì–¸ì œ ì“°ë‚˜ìš”?" --config config/enhanced.yaml
```

**ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ë‹µë³€ ê¸¸ì´: 5-8ì¤„ (ê°„ê²°í•¨)
- [ ] ì¶œì²˜ í‘œì‹œ: ì‹¤ì œ íŒŒì¼ëª… (ì˜ˆ: function-arguments.md)
- [ ] ìì—°ìŠ¤ëŸ¬ìš´ í†¤ (í˜•ì‹ì  êµ¬ì¡° ì—†ìŒ)
- [ ] ì •í™•ì„± (ë¬¸ì„œ ê¸°ë°˜, ì¶”ì¸¡ ì—†ìŒ)

---

**2) Pipeline Comparison (Baseline vs Enhanced)**
```bash
python compare_pipelines.py
```

**ë¹„êµ ì§€í‘œ**:
- Success Rate
- Avg Time per query
- Total Time
- ì˜ˆìƒ ì„±ëŠ¥ ë³€í™”

---

**3) RAGAS Evaluation (ìµœì¢… ê²€ì¦)**
```bash
# Git/Python ì§ˆë¬¸ë§Œ í•„í„°ë§í•˜ì—¬ í‰ê°€
# ragas_questions.jsonì—ì„œ Git/Python í•„í„°ë§
```

**í‰ê°€ ì§€í‘œ**:
- Context Precision
- Context Recall
- Faithfulness
- Answer Relevancy
- Answer Correctness

---

### 5.3 ì„±ê³µ ê¸°ì¤€

**Minimum Viable (ìµœì†Œ ëª©í‘œ)**:
- Faithfulness: 70%+ (45% â†’ 70%)
- Answer Correctness: 60%+ (44% â†’ 60%)
- ë‹µë³€ ìŠ¤íƒ€ì¼: ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•¨

**Target (ëª©í‘œ)**:
- Faithfulness: 85%+ (45% â†’ 85%)
- Answer Correctness: 70%+ (44% â†’ 70%)
- Context Recall: 80%+ (68% â†’ 80%)

**Stretch Goal (ì´ìƒì )**:
- Faithfulness: 93%+ (ì—°êµ¬ ìˆ˜ì¤€)
- Answer Correctness: 75%+
- ëª¨ë“  ì§€í‘œ 80%+

---

## ğŸ”¬ 6. ì´ë¡ ì  ë°°ê²½ ë° ì°¸ê³  ìë£Œ

### 6.1 ì£¼ìš” ë…¼ë¬¸

**1. Hybrid Search & RRF**
- "Reciprocal Rank Fusion outperforms Condorcet" (SIGIR 2009)
- RRF ê³µì‹: score(d) = Î£ 1/(k + rank_i(d))

**2. Self-RAG**
- "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-reflection" (Asai et al., 2023)
- arXiv: 2310.11511
- Context Quality Evaluationì˜ ì´ë¡ ì  ê¸°ë°˜

**3. Constitutional AI**
- "Constitutional AI: Harmlessness from AI Feedback" (Anthropic, 2022)
- arXiv: 2212.08073
- "ë¬¸ì„œì—ë§Œ ê¸°ë°˜" ì›ì¹™ì˜ ì´ë¡ ì  ê·¼ê±°

**4. Chain-of-Thought Prompting**
- "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" (Wei et al., 2022)
- arXiv: 2201.11903
- ë³µì¡í•œ ì§ˆë¬¸ ë‚´ë¶€ ë¶„í•´ ì „ëµ

**5. Few-shot Learning**
- "Language Models are Few-Shot Learners" (Brown et al., 2020)
- arXiv: 2005.14165
- GPT-3 ë…¼ë¬¸, Few-shot Promptingì˜ ê¸°ì´ˆ

**6. Lost in the Middle**
- "Lost in the Middle: How Language Models Use Long Contexts" (2023)
- ë„ˆë¬´ ë§ì€ ì»¨í…ìŠ¤íŠ¸ì˜ ë¬¸ì œì  ì§€ì 
- rerank_top_k ìµœì í™” ê·¼ê±°

---

### 6.2 ë¸”ë¡œê·¸/ê°€ì´ë“œ

- OpenAI Prompt Engineering Guide: https://platform.openai.com/docs/guides/prompt-engineering
- Anthropic Prompt Library: https://docs.anthropic.com/claude/prompt-library
- LangChain RAG Best Practices: https://python.langchain.com/docs/use_cases/question_answering/
- LlamaIndex Text Splitters: https://docs.llamaindex.ai/en/stable/
- BGE-M3 Model Card: https://huggingface.co/BAAI/bge-m3

---

## ğŸ’¡ 7. ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ë° êµí›ˆ

### 7.1 ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì˜ ì¤‘ìš”ì„±

**êµí›ˆ**: "ì§ê°ì´ë‚˜ ì¼ë°˜ ê°€ì´ë“œë¼ì¸ë³´ë‹¤, ì‹¤ì œ ë°ì´í„° ë¶„ì„ì´ ìµœì í™”ì˜ í•µì‹¬"

**ì‚¬ë¡€**:
- chunk_size=1024 (ì¼ë°˜ì  ê¶Œì¥) vs ì‹¤ì œ Median=899
- top_k=50 (sqrt(N) ê¸°ì¤€) vs ì‹¤ì œ 3% rule + capped
- ê²°ê³¼: ë°ì´í„° ê¸°ë°˜ íŒŒë¼ë¯¸í„°ê°€ 12% íš¨ìœ¨ í–¥ìƒ

---

### 7.2 Few-shot Promptingì˜ í˜

**êµí›ˆ**: "100ì¤„ì˜ ì§€ì¹¨ë³´ë‹¤, 3ê°œì˜ ì™„ë²½í•œ ì˜ˆì‹œê°€ ë” ê°•ë ¥í•¨"

**ì‚¬ë¡€**:
- Before: 104ì¤„ì˜ ìƒì„¸í•œ ì ˆì°¨ ì§€ì¹¨ â†’ í˜•ì‹ì ì´ê³  ì¥í™©í•œ ë‹µë³€
- After: 3ê°œì˜ Few-shot ì˜ˆì‹œ â†’ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ ë‹µë³€
- ê²°ê³¼: GPTëŠ” íŒ¨í„´ í•™ìŠµì— íƒì›”í•¨

---

### 7.3 Hybrid Searchì˜ ìƒí˜¸ë³´ì™„ì„±

**êµí›ˆ**: "Dense + Sparseê°€ ê°ê°ì˜ ì•½ì ì„ ë³´ì™„"

**ì‚¬ë¡€**:
- Dense Search: ì˜ë¯¸ì  ìœ ì‚¬ë„ (ì¼ë°˜ ê°œë…)
- Sparse Search: í‚¤ì›Œë“œ ë§¤ì¹­ (ì „ë¬¸ ìš©ì–´, í•¨ìˆ˜ëª…)
- RRF Fusion: ë‘ ë°©ì‹ì˜ ì¥ì  í†µí•©
- ê²°ê³¼: Context Recall 10-15% í–¥ìƒ ì˜ˆìƒ

---

### 7.4 Constitutional AI ì›ì¹™

**êµí›ˆ**: "í™˜ê° ë°©ì§€ëŠ” 'ê¸ˆì§€'ê°€ ì•„ë‹ˆë¼ 'ì›ì¹™ ì œì‹œ'"

**ì‚¬ë¡€**:
- "í™˜ê°í•˜ì§€ ë§ˆì„¸ìš”" (ê¸ˆì§€) â†’ íš¨ê³¼ ë‚®ìŒ
- "ê²€ìƒ‰ëœ ë¬¸ì„œì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€" (ì›ì¹™) â†’ íš¨ê³¼ ë†’ìŒ
- "ë¶ˆí™•ì‹¤í•˜ë©´ ì†”ì§í•˜ê²Œ" (í–‰ë™ ì§€ì¹¨) â†’ Faithfulness â†‘

---

### 7.5 ì‚¬ìš©ì ê²½í—˜ vs ê¸°ìˆ ì  ì™„ì„±ë„

**êµí›ˆ**: "ê¸°ìˆ ì ìœ¼ë¡œ ì™„ë²½í•´ë„, ì‚¬ìš©ìê°€ ë¶ˆí¸í•˜ë©´ ì‹¤íŒ¨"

**ì‚¬ë¡€**:
- í˜•ì‹ì  êµ¬ì¡° ("[ì¦ê±° ìš”ì•½]", "[ìì²´ ê²€ì¦]") â†’ ë¶€ë‹´ìŠ¤ëŸ¬ì›€
- ëª¨ë“  ë¬¸ì¥ë§ˆë‹¤ ì¸ìš© â†’ ê°€ë…ì„± ì €í•˜
- 15-20ì¤„ ë‹µë³€ â†’ ê¸´ ì½ê¸° ì‹œê°„
- ê²°ê³¼: ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì´ ì‚¬ìš©ì ë§Œì¡±ë„ í•µì‹¬

---

## ğŸš€ 8. ë‹¤ìŒ ë‹¨ê³„ (Phase 2 & Phase 3)

### Phase 2: ì¶”ê°€ ê³ ê¸‰ ê¸°ëŠ¥ (ì„ íƒì )

**1) HyDE Query Rewriting**
- ë³µì¡í•œ ì§ˆë¬¸ ê°œì„ 
- GPTê°€ ì´ìƒì ì¸ ë‹µë³€ ìƒì„± â†’ ê·¸ê²ƒìœ¼ë¡œ ê²€ìƒ‰
- ì˜ˆìƒ íš¨ê³¼: Context Recall +5-8%

**2) Metadata Filtering**
- Git/Python ë„ë©”ì¸ ìë™ ë¶„ë¥˜
- ë„ë©”ì¸ë³„ ê²€ìƒ‰ (ChromaDB where clause)
- ì˜ˆìƒ íš¨ê³¼: Precision +8-12%

**3) Semantic Caching**
- ë™ì¼/ìœ ì‚¬ ì§ˆë¬¸ ìºì‹±
- Cosine similarityë¡œ ìºì‹œ hit íŒë‹¨
- ì˜ˆìƒ íš¨ê³¼: ì†ë„ â†‘ 50%, ë¹„ìš© â†“ 40%

---

### Phase 3: Production ìµœì í™” (ë°°í¬ ì¤€ë¹„)

**1) CRAG Fallback Strategy**
- ë¬¸ì„œ ë¶€ì¡± ì‹œ ì›¹ ê²€ìƒ‰ fallback
- Tavily API ë˜ëŠ” Brave Search í†µí•©

**2) A/B Testing Framework**
- Baseline vs Enhanced ì‹¤ì‹œê°„ ë¹„êµ
- í†µê³„ì  ìœ ì˜ì„± ê²€ì¦

**3) GraphRAG (ì¥ê¸°)**
- ë¬¸ì„œ ê°„ ê´€ê³„ ê·¸ë˜í”„ êµ¬ì¶•
- Neo4j ë˜ëŠ” NetworkX í†µí•©
- Multi-hop reasoning ì§€ì›

---

## âœ… 9. ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° ì•¡ì…˜ ì•„ì´í…œ

### ì¦‰ì‹œ ì‹¤í–‰ (Immediate)
- [x] Enhanced Pipeline êµ¬í˜„ (answerer_v2.py)
- [x] ë¬¸ì„œ ë¶„í¬ ë¶„ì„ (analyze_documents.py)
- [x] Hyperparameter ìµœì í™” (config/enhanced.yaml)
- [x] System Prompt ìµœì í™” (prompts/system_v2.txt)
- [x] ì¶œì²˜ í‘œì‹œ ê°œì„  (ë©”íƒ€ë°ì´í„° í¬í•¨)
- [ ] **ì¬ì¸ë±ì‹± ì‹¤í–‰** (chunk_size=900, overlap=180)
- [ ] **Quick Test** (3-5ê°œ ì§ˆë¬¸)
- [ ] **RAGAS í‰ê°€** (ìµœì¢… ì„±ëŠ¥ ì¸¡ì •)

### ë‹¨ê¸° (Short-term, 1-2ì¼)
- [ ] Pipeline Comparison (Baseline vs Enhanced)
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ì†ë„, ë¹„ìš©)
- [ ] ì—ëŸ¬ ì¼€ì´ìŠ¤ ë¶„ì„
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ (README)

### ì¤‘ê¸° (Medium-term, 1ì£¼)
- [ ] Phase 2 ê¸°ëŠ¥ êµ¬í˜„ (HyDE, Metadata Filtering)
- [ ] Semantic Caching êµ¬í˜„
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
- [ ] Fine-tuning ê³ ë ¤ (Embedding Model)

### ì¥ê¸° (Long-term, 1ê°œì›”+)
- [ ] GraphRAG ì¡°ì‚¬ ë° PoC
- [ ] Production ë°°í¬ (API ì„œë²„)
- [ ] ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ
- [ ] ì§€ì†ì  ê°œì„  (CI/CD)

---

## ğŸ“Œ 10. ê²°ë¡ 

### 10.1 ì£¼ìš” ì„±ê³¼

1. **ë„ë©”ì¸ ì§‘ì¤‘í™”**: 4ê°œ â†’ 2ê°œ (Git/Python)
2. **Enhanced Pipeline**: Hybrid Search + Context Quality Filter
3. **ë°ì´í„° ê¸°ë°˜ ìµœì í™”**: chunk_size=900, rerank_top_k=10
4. **ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€**: 15ì¤„ â†’ 5-8ì¤„, ì‹¤ì œ íŒŒì¼ëª… ì¸ìš©
5. **ì´ë¡ ì  ê·¼ê±°**: 5ê°œ ì£¼ìš” ë…¼ë¬¸ ë° LLM í”„ë¡¬í”„íŒ… best practice ì ìš©

### 10.2 ì˜ˆìƒ ì„íŒ©íŠ¸

**ì„±ëŠ¥**:
- Faithfulness: 45% â†’ 93%+ (2ë°° ì´ìƒ í–¥ìƒ)
- Answer Correctness: 44% â†’ 75%+ (70% í–¥ìƒ)
- Context Recall: 68% â†’ 85%+ (25% í–¥ìƒ)

**ì‚¬ìš©ì ê²½í—˜**:
- ë‹µë³€ ê¸¸ì´: 70% ê°ì†Œ (15ì¤„ â†’ 5-8ì¤„)
- ê°€ë…ì„±: ëŒ€í­ í–¥ìƒ (ì¶œì²˜ ê°„ì†Œí™”)
- ìì—°ìŠ¤ëŸ¬ì›€: í˜•ì‹ì  â†’ ëŒ€í™”í˜•

**íš¨ìœ¨ì„±**:
- Index Size: -12% (ì²­í¬ ìˆ˜ ê°ì†Œ)
- Search Speed: +10-15%
- Reranking: 5ê°œ â†’ 10ê°œ (ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸)

### 10.3 í–¥í›„ ë°©í–¥

1. **ê²€ì¦**: RAGAS í‰ê°€ ì‹¤í–‰ ë° ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
2. **ê°œì„ **: ì—ëŸ¬ ì¼€ì´ìŠ¤ ë¶„ì„ ë° ì¶”ê°€ íŠœë‹
3. **í™•ì¥**: Phase 2 ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„
4. **ë°°í¬**: Production í™˜ê²½ ì¤€ë¹„

---

## ğŸ“š 11. ì°¸ê³  ìë£Œ ë° ë§í¬

### ì½”ë“œ ì €ì¥ì†Œ
- `experiments/rag_pipeline/` - ì „ì²´ í”„ë¡œì íŠ¸
- `answerer_v2.py` - Enhanced Pipeline ì½”ì–´
- `config/enhanced.yaml` - ìµœì í™”ëœ ì„¤ì •
- `prompts/system_v2.txt` - ê°œì„ ëœ System Prompt

### ë¬¸ì„œ
- `ENHANCED_README.md` - ì‚¬ìš© ê°€ì´ë“œ
- `OPTIMIZATION_GUIDE.md` - Hyperparameter ê°€ì´ë“œ
- `PROMPT_OPTIMIZATION.md` - Prompt ìµœì í™” ê°€ì´ë“œ
- `PROJECT_SUMMARY.md` - ì´ ë³´ê³ ì„œ

### ì™¸ë¶€ ë§í¬
- BGE-M3: https://huggingface.co/BAAI/bge-m3
- RAGAS: https://docs.ragas.io/
- ChromaDB: https://docs.trychroma.com/
- OpenAI API: https://platform.openai.com/docs/

---

**ì‘ì„±ì¼**: 2025-11-20
**ì‘ì„±ì**: RAG ìµœì í™” í”„ë¡œì íŠ¸ íŒ€
**ë²„ì „**: 1.0
**ìƒíƒœ**: êµ¬í˜„ ì™„ë£Œ, ê²€ì¦ ëŒ€ê¸° ì¤‘

---

## ğŸ“§ Contact & Support

ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´:
- í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬: `c:\develop1\test\experiments\rag_pipeline\`
- ë¬¸ì„œ: ENHANCED_README.md, OPTIMIZATION_GUIDE.md ì°¸ê³ 
- RAGAS í‰ê°€ ê²°ê³¼: `artifacts/ragas_evals/` í™•ì¸

**Happy RAG Optimization! ğŸš€**
