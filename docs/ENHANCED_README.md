# Enhanced RAG Pipeline - Hybrid Search + Context Quality Filter

## ğŸš€ ìƒˆë¡œìš´ ê¸°ëŠ¥

### 1. **Hybrid Search (Dense + Sparse + RRF)**
- **Dense Search**: BGE-M3 semantic embeddings (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰)
- **Sparse Search**: BGE-M3 lexical weights (í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰, BM25-like)
- **RRF (Reciprocal Rank Fusion)**: ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœì  ê²°í•©

**ê¸°ëŒ€ íš¨ê³¼:**
- Context Precision: +10-15%
- Context Recall: +10-15%

### 2. **Context Quality Filter (Self-RAG ìŠ¤íƒ€ì¼)**
- ê²€ìƒ‰ëœ ê° ë¬¸ì„œë¥¼ LLMìœ¼ë¡œ í‰ê°€
- RELEVANT / PARTIAL / IRRELEVANT ë¶„ë¥˜
- í’ˆì§ˆ ë‚®ì€ ë¬¸ì„œ ìë™ í•„í„°ë§

**ê¸°ëŒ€ íš¨ê³¼:**
- Faithfulness: +15-20% (í™˜ê° ê°ì†Œ)
- Answer Correctness: +8-12%

---

## ğŸ“‹ ì‹œìŠ¤í…œ ë¹„êµ

### Baseline (answerer.py)
```
[Query]
  â†“
[BGE-M3 Dense] â†’ Top 25
  â†“
[Stage 1 Reranker] â†’ Top 25
  â†“
[Stage 2 Reranker] â†’ Top 5
  â†“
[GPT-4 Generation]
```

### Enhanced (answerer_v2.py)
```
[Query]
  â†“
[BGE-M3 Dense + Sparse Encoding]
  â†“
[Dense Search] â†’ Top 50
  â†“
[Sparse Search on Top 50]
  â†“
[RRF Fusion] â†’ Hybrid results
  â†“
[Stage 1 Reranker] â†’ Top 25
  â†“
[Stage 2 Reranker] â†’ Top 5
  â†“
[Context Quality Filter (gpt-4o-mini)] â†’ 3-5ê°œ
  â†“
[GPT-4 Generation]
```

---

## ğŸ”§ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í™˜ê²½ ì¤€ë¹„ (ì´ë¯¸ ì™„ë£Œë¨)
```bash
# BGE-M3 ëª¨ë¸ ì´ë¯¸ ì„¤ì¹˜ë¨
# ChromaDB ì´ë¯¸ ì„¤ì •ë¨
# OpenAI API Key ì´ë¯¸ ì„¤ì •ë¨
```

### 2. Enhanced Config ì‚¬ìš©
```bash
# ìƒˆ ì„¤ì • íŒŒì¼ì´ ìë™ ìƒì„±ë¨
config/enhanced.yaml
```

**ì£¼ìš” ë³€ê²½ì‚¬í•­:**
- `hybrid_dense_top_k: 50` (ë” ë§ì€ í›„ë³´ ê²€ìƒ‰)
- `hybrid_sparse_top_k: 50` (sparse ì¬ê²€ìƒ‰)
- `rrf_k: 60` (RRF ìƒìˆ˜)
- `context_quality.enabled: true` (í’ˆì§ˆ í•„í„° í™œì„±í™”)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### Quick Test
```bash
cd experiments/rag_pipeline

# ë‹¨ì¼ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
python answerer_v2.py "Gitì—ì„œ ë§ˆì§€ë§‰ ì»¤ë°‹ì„ ìˆ˜ì •í•˜ë ¤ë©´?" --config config/enhanced.yaml

# ì—¬ëŸ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
python test_enhanced.py
```

### ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸

#### 1. Baseline í‰ê°€
```bash
# ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ í‰ê°€ (answerer.py)
python ragas_benchmark.py --config config/base.yaml --output baseline_results
```

#### 2. Enhanced í‰ê°€
```bash
# í–¥ìƒëœ ì‹œìŠ¤í…œìœ¼ë¡œ í‰ê°€ (answerer_v2.py)
python ragas_benchmark.py --config config/enhanced.yaml --answerer answerer_v2 --output enhanced_results
```

**ì£¼ì˜:** `ragas_benchmark.py`ëŠ” `answerer_v2.py`ë¥¼ importí•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì • í•„ìš”

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ

### Before (Baseline - ì„ í–‰ ê²°ê³¼ ê¸°ì¤€)
```
Git/Python 15ë¬¸ì œ í‰ê°€:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Context Precision:   67.5%
Context Recall:      63.3%
Faithfulness:        85.9%
Answer Relevancy:    77.4%
Answer Correctness:  59.6%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Overall Score:       70.7%
```

### After (Enhanced - ì˜ˆìƒ)
```
Git/Python 15ë¬¸ì œ í‰ê°€:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Context Precision:   77-80%  (+10-13%)
Context Recall:      73-78%  (+10-15%)
Faithfulness:        93-96%  (+7-10%)
Answer Relevancy:    82-85%  (+5-8%)
Answer Correctness:  68-72%  (+8-12%)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Overall Score:       79-82% (+8-11%)
```

---

## ğŸ” ì„¸ë¶€ ê¸°ëŠ¥ ì„¤ëª…

### 1. Hybrid Search

**ë¬¸ì œ:** Dense-only searchëŠ” í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•½í•¨
```
ì§ˆë¬¸: "git commit --amend ì‚¬ìš©ë²•"
Denseë§Œ: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ (ë•Œë¡œ ì •í™•í•œ ëª…ë ¹ì–´ ë†“ì¹¨)
Hybrid: Dense(ì˜ë¯¸) + Sparse(í‚¤ì›Œë“œ) ê²°í•©
```

**êµ¬í˜„ í•µì‹¬:**
```python
# answerer_v2.py Line 109-115
query_encoding = self.embedding_model.encode(
    [question],
    return_dense=True,   # ì˜ë¯¸ ë²¡í„°
    return_sparse=True,  # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
)

# RRFë¡œ ê²°í•©
rrf_scores[doc] = 1/(k + dense_rank) + 1/(k + sparse_rank)
```

### 2. Context Quality Filter

**ë¬¸ì œ:** Rerankerë„ ê°€ë” ë¬´ê´€í•œ ë¬¸ì„œë¥¼ í†µê³¼ì‹œí‚´

**í•´ê²°:** LLMìœ¼ë¡œ ê° ë¬¸ì„œ í‰ê°€
```python
# answerer_v2.py Line 175-210
for ctx in contexts:
    # gpt-4o-minië¡œ í‰ê°€ (ì €ë ´)
    label = evaluate_relevance(question, ctx)

    if label == "RELEVANT":
        final_contexts.append(ctx)
    elif label == "IRRELEVANT":
        # í•„í„°ë§
        pass
```

**ë¹„ìš©:**
- ë¬¸ì„œ 5ê°œ í‰ê°€: ~$0.001 (ë§¤ìš° ì €ë ´)
- Faithfulness ëŒ€í­ í–¥ìƒ

---

## âš™ï¸ ì„¤ì • ì˜µì…˜

### Hybrid Search íŠœë‹
```yaml
retrieval:
  hybrid_dense_top_k: 50   # ëŠ˜ë¦¬ë©´: Recall â†‘, ì†ë„ â†“
  hybrid_sparse_top_k: 50  # Dense í›„ë³´ì—ì„œ sparse ì¬ê²€ìƒ‰
  rrf_k: 60                # 60ì´ ë…¼ë¬¸ í‘œì¤€ (40-80 ë²”ìœ„)
```

### Context Quality íŠœë‹
```yaml
context_quality:
  enabled: true            # falseë¡œ í•˜ë©´ ë¹„í™œì„±í™”
  threshold: 0.6           # ë¯¸ë˜ í™•ì¥ìš©
  evaluator_model: gpt-4o-mini  # ë˜ëŠ” gpt-3.5-turbo
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. "Sparse search failed"
```bash
# BGE-M3 ëª¨ë¸ì´ sparseë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
python -c "from FlagEmbedding import BGEM3FlagModel; print('OK')"
```

### 2. "Context quality evaluation timeout"
```bash
# gpt-4o-mini API í‚¤ í™•ì¸
echo $OPENAI_API_KEY

# ë˜ëŠ” ë¹„í™œì„±í™”
# config/enhanced.yamlì—ì„œ context_quality.enabled: false
```

### 3. "No relevant contexts found"
```
ë¡œê·¸ì—ì„œ í™•ì¸:
- "Context quality filter: 0/5 kept" â†’ ëª¨ë“  ë¬¸ì„œê°€ IRRELEVANT
- í•´ê²°: ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ threshold ë‚®ì¶¤
```

---

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ ë¶„ì„
```bash
# Enhanced pipeline ì‹¤í–‰ ì‹œ ë¡œê·¸ í™•ì¸
python answerer_v2.py "ì§ˆë¬¸" --log-level DEBUG

# ì£¼ìš” ì§€í‘œ:
# - Dense retrieval: XXXms
# - Sparse search: XXXms
# - RRF fusion: XXXms
# - Context quality filter: X/Y kept
```

### ë³‘ëª© ì§€ì 
```
ì¼ë°˜ì ì¸ ì‹œê°„ ë¶„í¬:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Query encoding:     50-100ms
Dense retrieval:    100-200ms
Sparse search:      200-400ms  â† ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¼
RRF fusion:         10-20ms
Stage 1 rerank:     300-500ms
Stage 2 rerank:     200-300ms
Quality filter:     500-800ms  â† LLM í˜¸ì¶œ
LLM generation:     1000-2000ms
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total:             ~3-4ì´ˆ (Baseline ëŒ€ë¹„ +1ì´ˆ)
```

**ìµœì í™” ë°©ë²•:**
- Sparse searchë¥¼ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
- Quality filterë¥¼ batchë¡œ ì²˜ë¦¬
- ìºì‹± ì¶”ê°€

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Phase 2)

í˜„ì¬ êµ¬í˜„: **Phase 1 ì™„ë£Œ**
- âœ… Hybrid Search (Dense + Sparse + RRF)
- âœ… Context Quality Filter (Self-RAG)

ì¶”ê°€ ê°€ëŠ¥ ê¸°ëŠ¥:
1. **Query Rewriting (HyDE)** - ë³µì¡í•œ ì§ˆë¬¸ ê°œì„ 
2. **Metadata Filtering** - ë„ë©”ì¸ë³„ ê²€ìƒ‰ (git/python)
3. **Semantic Caching** - ë™ì¼ ì§ˆë¬¸ ìºì‹±
4. **Fallback Strategy (CRAG)** - ë¬¸ì„œ ë¶€ì¡± ì‹œ ì›¹ ê²€ìƒ‰

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
1. **Self-RAG** (ICLR 2024)
   - "Self-Reflective Retrieval-Augmented Generation"
   - Context quality evaluation ì•„ì´ë””ì–´ ì¶œì²˜

2. **RRF** (SIGIR 2009)
   - "Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods"
   - Hybrid search fusion í‘œì¤€ ë°©ë²•

3. **BGE-M3** (2024)
   - "BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation"
   - Dense + Sparse + ColBERT ì§€ì›

### GitHub
- [FlagEmbedding (BGE)](https://github.com/FlagOpen/FlagEmbedding)
- [LlamaIndex Hybrid Search](https://docs.llamaindex.ai/en/stable/examples/retrievers/bm25_retriever.html)

---

## ğŸ“ ì§€ì›

ë¬¸ì œ ë°œìƒ ì‹œ:
1. ë¡œê·¸ í™•ì¸: `--log-level DEBUG`
2. Config ê²€ì¦: `config/enhanced.yaml`
3. Baselineê³¼ ë¹„êµ: `answerer.py` vs `answerer_v2.py`

**Known Issues:**
- Windows CPU ëª¨ë“œì—ì„œ sparse searchê°€ ëŠë¦´ ìˆ˜ ìˆìŒ (ì •ìƒ)
- gpt-4o-mini API ì†ë„ì œí•œ ì‹œ context quality filter íƒ€ì„ì•„ì›ƒ ê°€ëŠ¥
