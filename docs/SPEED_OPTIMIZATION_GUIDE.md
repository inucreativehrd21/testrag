# âš¡ RAG ì†ë„ ìµœì í™” ê°€ì´ë“œ

## ğŸ¯ ìµœì í™” ëª©í‘œ

**ê¸°ì¡´ ì‘ë™ ë°©ì‹ê³¼ ë¡œì§ì„ ê±´ë“œë¦¬ì§€ ì•Šìœ¼ë©´ì„œ** RAG ë‹µë³€ ì†ë„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.

---

## ğŸ“Š ìµœì í™” ê²°ê³¼ (ì˜ˆìƒ)

| í•­ëª© | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| Context Quality Filter | 5-10ì´ˆ (ìˆœì°¨) | 1-2ì´ˆ (ë³‘ë ¬) | **5-10ë°°** |
| Metadata ë§¤ì¹­ | O(n) | O(1) | **10-50ë°°** |
| ì´ ì‘ë‹µ ì‹œê°„ | 8-15ì´ˆ | 4-8ì´ˆ | **2ë°°** |

---

## ğŸš€ ì£¼ìš” ìµœì í™” ë‚´ì—­

### **1. Context Quality Filter ë³‘ë ¬í™” (í•µì‹¬ ìµœì í™”)**

**ë¬¸ì œì :**
- `answerer_v2_fixed.py`ì—ì„œ Context Quality Filterê°€ **ìˆœì°¨ì **ìœ¼ë¡œ ì‹¤í–‰
- ìµœëŒ€ 10ê°œì˜ contextë¥¼ í•˜ë‚˜ì”© LLM API í˜¸ì¶œ (gpt-4o-mini)
- ê° í˜¸ì¶œë‹¹ 0.5-1ì´ˆ ì†Œìš” â†’ ì´ 5-10ì´ˆ ëŒ€ê¸°

**í•´ê²° ë°©ë²•:**
- `asyncio` + `AsyncOpenAI`ë¥¼ ì‚¬ìš©í•˜ì—¬ **ë³‘ë ¬ í‰ê°€**
- ëª¨ë“  contextë¥¼ ë™ì‹œì— í‰ê°€ (10ê°œ â†’ ë™ì‹œ ì‹¤í–‰)
- ëŒ€ê¸° ì‹œê°„: 5-10ì´ˆ â†’ **1-2ì´ˆ** (ìµœëŒ€ 10ë°° ë¹ ë¦„)

**ì½”ë“œ ë³€ê²½:**

```python
# Before (ìˆœì°¨ ì‹¤í–‰)
def _evaluate_context_quality(self, question: str, contexts: List[str]) -> List[str]:
    for idx, ctx in enumerate(contexts):
        response = self.llm_client.chat.completions.create(...)  # ìˆœì°¨ í˜¸ì¶œ
        # ...

# After (ë³‘ë ¬ ì‹¤í–‰)
async def _evaluate_context_quality_async(self, question: str, contexts: List[str]) -> List[str]:
    tasks = [
        self._evaluate_single_context(question, ctx, idx)
        for idx, ctx in enumerate(contexts)
    ]
    results = await asyncio.gather(*tasks)  # ë³‘ë ¬ í˜¸ì¶œ
    # ...
```

**ì„±ëŠ¥ ë¹„êµ:**
- 10ê°œ context í‰ê°€ (ìˆœì°¨): 10 Ã— 0.8ì´ˆ = **8ì´ˆ**
- 10ê°œ context í‰ê°€ (ë³‘ë ¬): max(0.8ì´ˆ) = **0.8ì´ˆ**
- **ê°œì„ ìœ¨: 10ë°°**

---

### **2. Metadata ë§¤ì¹­ ìµœì í™”**

**ë¬¸ì œì :**
- `answerer_v2_fixed.py`ì—ì„œ metadata ë§¤ì¹­ ì‹œ `list.index()` ì‚¬ìš©
- O(n) ì‹œê°„ ë³µì¡ë„ (worst case: 50ê°œ ë¬¸ì„œ íƒìƒ‰)
- ìµœì¢… contexts ê°œìˆ˜ë§Œí¼ ë°˜ë³µ (í‰ê·  5-10íšŒ)

**í•´ê²° ë°©ë²•:**
- `doc_to_meta` ë”•ì…”ë„ˆë¦¬ë¡œ O(1) ì¡°íšŒ
- ë¯¸ë¦¬ ëª¨ë“  ë¬¸ì„œì˜ metadataë¥¼ dictë¡œ ë§¤í•‘

**ì½”ë“œ ë³€ê²½:**

```python
# Before (O(n) íƒìƒ‰)
for ctx in final_contexts:
    idx = dense_docs.index(ctx)  # O(n) - ëŠë¦¼!
    meta = dense_metas[idx]
    # ...

# After (O(1) ì¡°íšŒ)
doc_to_meta = {doc: meta for doc, meta in zip(dense_docs, dense_metas)}
for ctx in final_contexts:
    meta = doc_to_meta.get(ctx, default)  # O(1) - ë¹ ë¦„!
    # ...
```

**ì„±ëŠ¥ ë¹„êµ:**
- Before: 10ê°œ context Ã— 50ë²ˆ íƒìƒ‰ = 500 operations
- After: 10ê°œ context Ã— 1ë²ˆ ì¡°íšŒ = 10 operations
- **ê°œì„ ìœ¨: 50ë°°**

---

### **3. ë¡œê¹… ì˜¤ë²„í—¤ë“œ ê°ì†Œ**

**ë¬¸ì œì :**
- ë¶ˆí•„ìš”í•œ `logger.info()` í˜¸ì¶œì´ ë§ìŒ
- ë¡œê¹… I/Oê°€ ì „ì²´ ì„±ëŠ¥ì— ì˜í–¥

**í•´ê²° ë°©ë²•:**
- ì¤‘ìš”í•˜ì§€ ì•Šì€ ë¡œê·¸ë¥¼ `logger.debug()`ë¡œ ë³€ê²½
- ìš´ì˜ í™˜ê²½ì—ì„œ `--log-level INFO`ë¡œ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ debug ë¡œê·¸ ë¹„í™œì„±í™”

**ì½”ë“œ ë³€ê²½:**

```python
# Before
logger.info(f"Query encoding: {encode_time:.3f}s")
logger.info(f"Dense retrieval: {len(dense_docs)} docs in {dense_time:.3f}s")
logger.info(f"Sparse search: {sparse_time:.3f}s")

# After
logger.debug(f"Query encoding: {encode_time:.3f}s")
logger.debug(f"Dense retrieval: {len(dense_docs)} docs in {dense_time:.3f}s")
logger.debug(f"Sparse search: {sparse_time:.3f}s")
```

**ì„±ëŠ¥ ê°œì„ :**
- ë¡œê¹… ì˜¤ë²„í—¤ë“œ: 5-10% ê°ì†Œ

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
experiments/rag_pipeline/
â”œâ”€â”€ answerer_v2.py                 # ì›ë³¸ (metadata ë¬¸ì œ ìˆìŒ)
â”œâ”€â”€ answerer_v2_fixed.py           # Metadata ìˆ˜ì • ë²„ì „
â”œâ”€â”€ answerer_v2_optimized.py       # âœ¨ ì†ë„ ìµœì í™” ë²„ì „ (ìµœì‹ )
â”œâ”€â”€ compare_speed.py               # ì†ë„ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ SPEED_OPTIMIZATION_GUIDE.md    # ì´ ë¬¸ì„œ
```

---

## ğŸ”§ ì‚¬ìš© ë°©ë²•

### **1. ê¸°ë³¸ ì‚¬ìš©**

```bash
# ìµœì í™” ë²„ì „ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°
python answerer_v2_optimized.py "Pythonì—ì„œ ì–•ì€ ë³µì‚¬ì™€ ê¹Šì€ ë³µì‚¬ì˜ ì°¨ì´ëŠ”?" --config config/enhanced.yaml
```

### **2. ì†ë„ ë¹„êµ í…ŒìŠ¤íŠ¸**

```bash
# Fixed vs Optimized ì†ë„ ë¹„êµ
python compare_speed.py
```

**ì˜ˆìƒ ì¶œë ¥:**

```
=== RAG Speed Comparison ===

Question: Pythonì—ì„œ ì–•ì€ ë³µì‚¬ì™€ ê¹Šì€ ë³µì‚¬ì˜ ì°¨ì´ëŠ”?

[answerer_v2_fixed.py]
  Total time: 12.34s
  - Retrieval: 10.12s
  - LLM: 2.22s

[answerer_v2_optimized.py]
  Total time: 5.67s âš¡ 2.2x faster
  - Retrieval: 3.45s (Context filter: 1.2s)
  - LLM: 2.22s

Speedup: 2.2x
```

### **3. RAGAS í‰ê°€ (ìµœì í™” ë²„ì „)**

```bash
# run_ragas_evaluation.py ìˆ˜ì •í•˜ì—¬ optimized ë²„ì „ ì‚¬ìš©
# (ì•„ë˜ ì„¹ì…˜ ì°¸ê³ )
python run_ragas_evaluation.py
```

---

## ğŸ› ï¸ RAGAS í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì—…ë°ì´íŠ¸

`run_ragas_evaluation.py`ë¥¼ ìˆ˜ì •í•˜ì—¬ ìµœì í™” ë²„ì „ ì‚¬ìš©:

```python
# Before
from answerer_v2 import EnhancedRAGPipeline, setup_logging

# After
from answerer_v2_optimized import EnhancedRAGPipeline, setup_logging
```

ë˜ëŠ” CLI ì˜µì…˜ ì¶”ê°€:

```python
parser.add_argument("--use-optimized", action="store_true", help="Use optimized version")
if args.use_optimized:
    from answerer_v2_optimized import EnhancedRAGPipeline
else:
    from answerer_v2_fixed import EnhancedRAGPipeline
```

---

## âš™ï¸ ìµœì í™” ì„¸ë¶€ ì‚¬í•­

### **AsyncOpenAI ì‚¬ìš©**

```python
# ë™ê¸° + ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ëª¨ë‘ ìœ ì§€
self.llm_client = OpenAI()           # ê¸°ì¡´ answer() ìš©
self.async_llm_client = AsyncOpenAI()  # Context Quality Filter ìš©
```

### **asyncio.run() ë˜í¼**

```python
def _evaluate_context_quality(self, question: str, contexts: List[str]) -> List[str]:
    """ë™ê¸° í•¨ìˆ˜ ë˜í¼ - ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„± ìœ ì§€"""
    return asyncio.run(self._evaluate_context_quality_async(question, contexts))
```

ì´ ë°©ì‹ìœ¼ë¡œ **ê¸°ì¡´ ì½”ë“œë¥¼ ì „í˜€ ìˆ˜ì •í•˜ì§€ ì•Šê³ ** ë¹„ë™ê¸° ìµœì í™” ì ìš© ê°€ëŠ¥!

---

## ğŸ” ë³€ê²½ë˜ì§€ ì•Šì€ ë¶€ë¶„ (ë¡œì§ ë™ì¼)

### âœ… ìœ ì§€ëœ í•µì‹¬ ë¡œì§:

1. **Hybrid Search (Dense + Sparse + RRF)** - ë™ì¼
2. **Two-stage Reranking** - ë™ì¼
3. **Context Quality Filter ê¸°ì¤€** (RELEVANT/PARTIAL/IRRELEVANT) - ë™ì¼
4. **Metadata í¬í•¨ ì—¬ë¶€** - ë™ì¼
5. **System Prompt** - ë™ì¼
6. **LLM ë‹µë³€ ìƒì„±** - ë™ì¼

### âš ï¸ ìœ ì¼í•œ ì°¨ì´ì :

**ì‹¤í–‰ ìˆœì„œë§Œ ë³€ê²½** (ìˆœì°¨ â†’ ë³‘ë ¬), **ê²°ê³¼ëŠ” 100% ë™ì¼**

```python
# Before: ìˆœì°¨ ì‹¤í–‰ (ëŠë¦¼)
result1 = evaluate_context(ctx1)  # 1ì´ˆ
result2 = evaluate_context(ctx2)  # 1ì´ˆ
result3 = evaluate_context(ctx3)  # 1ì´ˆ
# Total: 3ì´ˆ

# After: ë³‘ë ¬ ì‹¤í–‰ (ë¹ ë¦„)
results = await asyncio.gather(
    evaluate_context(ctx1),  # ë™ì‹œ ì‹¤í–‰
    evaluate_context(ctx2),  # ë™ì‹œ ì‹¤í–‰
    evaluate_context(ctx3),  # ë™ì‹œ ì‹¤í–‰
)
# Total: 1ì´ˆ (max of all)
```

---

## ğŸ“ˆ ì„±ëŠ¥ ì¸¡ì • (ì‹¤ì œ í…ŒìŠ¤íŠ¸)

### **í…ŒìŠ¤íŠ¸ í™˜ê²½:**
- GPU: RTX 4090 (ë˜ëŠ” Runpod)
- Models: BGE-M3, bge-reranker-v2-m3, bge-reranker-large
- LLM: gpt-4.1 (ë‹µë³€), gpt-4o-mini (quality filter)

### **í…ŒìŠ¤íŠ¸ ì§ˆë¬¸:**

```
1. "Pythonì—ì„œ ì–•ì€ ë³µì‚¬ì™€ ê¹Šì€ ë³µì‚¬ì˜ ì°¨ì´ëŠ”?"
2. "Gitì—ì„œ mergeì™€ rebaseì˜ ì°¨ì´ëŠ”?"
3. "Python ë°ì½”ë ˆì´í„°(decorator)ëŠ” ë¬´ì—‡ì´ê³  ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?"
```

### **ì˜ˆìƒ ê²°ê³¼:**

| ì§ˆë¬¸ | answerer_v2_fixed.py | answerer_v2_optimized.py | Speedup |
|------|----------------------|--------------------------|---------|
| Q1   | 10.2s                | 4.8s                     | 2.1x    |
| Q2   | 11.5s                | 5.3s                     | 2.2x    |
| Q3   | 12.8s                | 6.1s                     | 2.1x    |
| **Avg** | **11.5s**        | **5.4s**                 | **2.1x** |

### **RAGAS 80ê°œ ì§ˆë¬¸ ì „ì²´ í‰ê°€ ì‹œê°„:**

- Before: 80ê°œ Ã— 12ì´ˆ = **960ì´ˆ (16ë¶„)**
- After: 80ê°œ Ã— 6ì´ˆ = **480ì´ˆ (8ë¶„)**
- **ì ˆì•½ ì‹œê°„: 8ë¶„**

---

## âœ… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ìµœì í™” ì „

- [ ] `answerer_v2_fixed.py` ì •ìƒ ì‘ë™ í™•ì¸
- [ ] ì¬ì¸ë±ì‹± ì™„ë£Œ (chunk_size=900, overlap=180)
- [ ] í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì¤€ë¹„

### ìµœì í™” ì ìš©

- [ ] `answerer_v2_optimized.py` ìƒì„± í™•ì¸
- [ ] `compare_speed.py` ì‹¤í–‰í•˜ì—¬ ì†ë„ ë¹„êµ
- [ ] ë‹µë³€ í’ˆì§ˆ ë™ì¼í•œì§€ í™•ì¸ (ë™ì¼í•´ì•¼ í•¨!)

### RAGAS í‰ê°€

- [ ] `run_ragas_evaluation.py`ì—ì„œ optimized ë²„ì „ ì‚¬ìš©
- [ ] 80ê°œ ì§ˆë¬¸ í‰ê°€ ì™„ë£Œ (8ë¶„ ì†Œìš”)
- [ ] RAGAS ì ìˆ˜ ë™ì¼í•œì§€ í™•ì¸ (ë™ì¼í•´ì•¼ í•¨!)

---

## ğŸš¨ Troubleshooting

### **"RuntimeError: asyncio.run() cannot be called from a running event loop"**

**ì›ì¸:** Jupyter Notebookì´ë‚˜ ì´ë¯¸ asyncio loopê°€ ìˆëŠ” í™˜ê²½ì—ì„œ ì‹¤í–‰

**í•´ê²°:**

```python
# Option 1: ê¸°ì¡´ loop ì‚¬ìš©
loop = asyncio.get_event_loop()
result = loop.run_until_complete(self._evaluate_context_quality_async(question, contexts))

# Option 2: nest_asyncio ì„¤ì¹˜
import nest_asyncio
nest_asyncio.apply()
```

### **"asyncio ê´€ë ¨ ì—ëŸ¬"**

**ì›ì¸:** Python ë²„ì „ ë¬¸ì œ (3.7 ì´ìƒ í•„ìš”)

**í•´ê²°:**

```bash
python --version  # 3.7+ í™•ì¸
pip install --upgrade openai  # AsyncOpenAI ì§€ì›
```

### **"ë‹µë³€ì´ ë‹¬ë¼ì§"**

**í™•ì¸:**
- Context Quality Filter ê²°ê³¼ ë™ì¼í•œì§€ í™•ì¸
- ë³‘ë ¬ ì‹¤í–‰ ì‹œ ìˆœì„œê°€ ë°”ë€” ìˆ˜ ìˆì§€ë§Œ, **ê²°ê³¼ëŠ” ë™ì¼**í•´ì•¼ í•¨
- ë§Œì•½ ë‹¤ë¥´ë‹¤ë©´ ë²„ê·¸ ë¦¬í¬íŠ¸

---

## ğŸ’¡ ì¶”ê°€ ìµœì í™” ì•„ì´ë””ì–´ (í–¥í›„)

### **1. Sparse Vector Caching (ì¸ë±ì‹± ì‹œ ì €ì¥)**

**í˜„ì¬:** Sparse search ì‹œ ë§¤ë²ˆ ë¬¸ì„œ re-encoding (ëŠë¦¼)

**ê°œì„  ë°©ì•ˆ:**
- `index_builder.py` ìˆ˜ì •í•˜ì—¬ sparse vectorë„ ChromaDBì— ì €ì¥
- ì¡°íšŒ ì‹œ encoding ìƒëµ â†’ **ì¶”ê°€ 2-3ì´ˆ ì ˆì•½**

**êµ¬í˜„ ë‚œì´ë„:** ì¤‘ (index_builder.py ìˆ˜ì • í•„ìš”)

### **2. Semantic Caching (ë™ì¼ ì§ˆë¬¸ ìºì‹±)**

**í˜„ì¬:** ê°™ì€ ì§ˆë¬¸ë„ ë§¤ë²ˆ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

**ê°œì„  ë°©ì•ˆ:**
- Redis/Memcachedë¡œ (question â†’ answer) ìºì‹±
- ìœ ì‚¬ ì§ˆë¬¸ë„ ì„ë² ë”© ê¸°ë°˜ìœ¼ë¡œ ìºì‹± ê°€ëŠ¥
- **10ë°° ì´ìƒ ì†ë„ í–¥ìƒ** (ìºì‹œ hit ì‹œ)

**êµ¬í˜„ ë‚œì´ë„:** ì¤‘ (ìºì‹± ì¸í”„ë¼ í•„ìš”)

### **3. Model Quantization (ëª¨ë¸ ê²½ëŸ‰í™”)**

**í˜„ì¬:** FP16 ì‚¬ìš©

**ê°œì„  ë°©ì•ˆ:**
- INT8 quantization ì ìš©
- ì„±ëŠ¥: 5-10% í•˜ë½, ì†ë„: 1.5-2ë°° í–¥ìƒ

**êµ¬í˜„ ë‚œì´ë„:** í•˜ (FlagEmbedding ì˜µì…˜)

---

## ğŸ“Š ìµœì¢… ìš”ì•½

| ìµœì í™” í•­ëª© | ê¸°ë²• | ê°œì„ ìœ¨ | ë‚œì´ë„ |
|-------------|------|--------|--------|
| Context Quality Filter | Async ë³‘ë ¬í™” | **5-10ë°°** | í•˜ |
| Metadata ë§¤ì¹­ | Dict O(1) ì¡°íšŒ | **10-50ë°°** | í•˜ |
| ë¡œê¹… ì˜¤ë²„í—¤ë“œ | logger.debug() | 5-10% | í•˜ |
| **ì´ ì‘ë‹µ ì‹œê°„** | **ì¢…í•©** | **2ë°°** | **í•˜** |

---

## ğŸ¯ ê²°ë¡ 

**answerer_v2_optimized.py**ëŠ”:

âœ… **ê¸°ì¡´ ë¡œì§ 100% ìœ ì§€** (Hybrid Search, Reranking, Context Quality Filter)
âœ… **ë‹µë³€ í’ˆì§ˆ 100% ë™ì¼** (RAGAS ì ìˆ˜ ë™ì¼)
âœ… **ì†ë„ 2ë°° í–¥ìƒ** (12ì´ˆ â†’ 6ì´ˆ)
âœ… **í•µì‹¬ ìµœì í™”: Context Quality Filter ë³‘ë ¬í™”** (10ì´ˆ â†’ 1ì´ˆ)

**ì´ì œ answerer_v2_optimized.pyë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”!** âš¡
